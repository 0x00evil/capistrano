require 'erb'
require 'capistrano/command'
require 'capistrano/transfer'
require 'capistrano/gateway'
require 'capistrano/ssh'
require 'capistrano/utils'

module Capistrano

  # An Actor is the entity that actually does the work of determining which
  # servers should be the target of a particular task, and of executing the
  # task on each of them in parallel. An Actor is never instantiated
  # directly--rather, you create a new Configuration instance, and access the
  # new actor via Configuration#actor.
  class Actor
    class <<self
      attr_accessor :default_io_proc
    end

    self.default_io_proc = Proc.new do |ch, stream, out|
      level = stream == :err ? :important : :info
      ch[:actor].logger.send(level, out, "#{stream} :: #{ch[:host]}")
    end

    def initialize(config) #:nodoc:
      @configuration = config
      @tasks = {}
      @task_call_frames = []
      @sessions = {}
      @factory = self.class.connection_factory.new(configuration)
    end

    # Execute the given command on all servers that are the target of the
    # current task. If a block is given, it is invoked for all output
    # generated by the command, and should accept three parameters: the SSH
    # channel (which may be used to send data back to the remote process),
    # the stream identifier (<tt>:err</tt> for stderr, and <tt>:out</tt> for
    # stdout), and the data that was received.
    #
    # If +pretend+ mode is active, this does nothing.
    def run(cmd, options={}, &block)
      block ||= default_io_proc
      logger.debug "executing #{cmd.strip.inspect}"

      execute_on_servers(options) do |servers|
        # execute the command on each server in parallel
        command = self.class.command_factory.new(servers, cmd, block, options, self)
        command.process! # raises an exception if command fails on any server
      end
    end

    # Streams the result of the command from all servers that are the target of the
    # current task. All these streams will be joined into a single one,
    # so you can, say, watch 10 log files as though they were one. Do note that this
    # is quite expensive from a bandwidth perspective, so use it with care.
    #
    # Example:
    #
    #   desc "Run a tail on multiple log files at the same time"
    #   task :tail_fcgi, :roles => :app do
    #     stream "tail -f #{shared_path}/log/fastcgi.crash.log"
    #   end
    def stream(command)
      run(command) do |ch, stream, out|
        puts out if stream == :out
        if stream == :err
          puts "[err : #{ch[:host]}] #{out}"
          break
        end
      end
    end

    # Deletes the given file from all servers targetted by the current task.
    # If <tt>:recursive => true</tt> is specified, it may be used to remove
    # directories.
    def delete(path, options={})
      cmd = "rm -%sf #{path}" % (options[:recursive] ? "r" : "")
      run(cmd, options)
    end

    # Store the given data at the given location on all servers targetted by
    # the current task. If <tt>:mode</tt> is specified it is used to set the
    # mode on the file.
    def put(data, path, options={})
      if Capistrano::SFTP
        execute_on_servers(options) do |servers|
          transfer = self.class.transfer_factory.new(servers, self, path, :data => data,
            :mode => options[:mode])
          transfer.process!
        end
      else
        # Poor-man's SFTP... just run a cat on the remote end, and send data
        # to it.

        cmd = "cat > #{path}"
        cmd << " && chmod #{options[:mode].to_s(8)} #{path}" if options[:mode]
        run(cmd, options.merge(:data => data + "\n\4")) do |ch, stream, out|
          logger.important out, "#{stream} :: #{ch[:host]}" if stream == :err
        end
      end
    end
    
    # Get file remote_path from FIRST server targetted by
    # the current task and transfer it to local machine as path. It will use
    # SFTP if Net::SFTP is installed; otherwise it will fall back to using
    # 'cat', which may cause corruption in binary files.
    #
    # get "#{deploy_to}/current/log/production.log", "log/production.log.web"
    def get(remote_path, path, options = {})
      if Capistrano::SFTP && options.fetch(:sftp, true)
        execute_on_servers(options.merge(:once => true)) do |servers|
          logger.debug "downloading #{servers.first}:#{remote_path} to #{path}" 
          sftp = sessions[servers.first].sftp
          sftp.connect unless sftp.state == :open
          sftp.get_file remote_path, path
          logger.trace "download finished" 
        end
      else
        logger.important "Net::SFTP is not available; using remote 'cat' to get file, which may cause file corruption"
        File.open(path, "w") do |destination|
          run "cat #{remote_path}", :once => true do |ch, stream, data|
            case stream
            when :out then destination << data
            when :err then raise "error while downloading #{remote_path}: #{data.inspect}"
            end
          end
        end
      end
    end

    # Executes the given command on the first server targetted by the current
    # task, collects it's stdout into a string, and returns the string.
    def capture(command, options={})
      output = ""
      run(command, options.merge(:once => true)) do |ch, stream, data|
        case stream
        when :out then output << data
        when :err then raise "error processing #{command.inspect}: #{data.inspect}"
        end
      end
      output
    end

    # Like #run, but executes the command via <tt>sudo</tt>. This assumes that
    # the sudo password (if required) is the same as the password for logging
    # in to the server.
    #
    # Also, this module accepts a <tt>:sudo</tt> configuration variable,
    # which (if specified) will be used as the full path to the sudo
    # executable on the remote machine:
    #
    #   set :sudo, "/opt/local/bin/sudo"
    def sudo(command, options={}, &block)
      block ||= default_io_proc

      # in order to prevent _each host_ from prompting when the password was
      # wrong, let's track which host prompted first and only allow subsequent
      # prompts from that host.
      prompt_host = nil      
      user = options[:as].nil? ? '' : "-u #{options[:as]}"
      
      run "#{sudo_command} #{user} #{command}", options do |ch, stream, out|
        if out =~ /^Password:/
          ch.send_data "#{password}\n"
        elsif out =~ /try again/
          if prompt_host.nil? || prompt_host == ch[:host]
            prompt_host = ch[:host]
            logger.important out, "#{stream} :: #{ch[:host]}"
            # reset the password to it's original value and prepare for another
            # pass (the reset allows the password prompt to be attempted again
            # if the password variable was originally a proc (the default)
            set :password, self[:original_value][:password] || self[:password]
          end
        else
          block.call(ch, stream, out)
        end
      end
    end

    # Renders an ERb template and returns the result. This is useful for
    # dynamically building documents to store on the remote servers.
    #
    # Usage:
    #
    #   render("something", :foo => "hello")
    #     look for "something.rhtml" in the current directory, or in the
    #     capistrano/recipes/templates directory, and render it with
    #     foo defined as a local variable with the value "hello".
    #
    #   render(:file => "something", :foo => "hello")
    #     same as above
    #
    #   render(:template => "<%= foo %> world", :foo => "hello")
    #     treat the given string as an ERb template and render it with
    #     the given hash of local variables active.
    def render(*args)
      options = args.last.is_a?(Hash) ? args.pop : {}
      options[:file] = args.shift if args.first.is_a?(String)
      raise ArgumentError, "too many parameters" unless args.empty?

      case
        when options[:file]
          file = options.delete :file
          unless file[0] == ?/
            dirs = [".",
              File.join(File.dirname(__FILE__), "recipes", "templates")]
            dirs.each do |dir|
              if File.file?(File.join(dir, file))
                file = File.join(dir, file)
                break
              elsif File.file?(File.join(dir, file + ".rhtml"))
                file = File.join(dir, file + ".rhtml")
                break
              end
            end
          end

          render options.merge(:template => File.read(file))

        when options[:template]
          erb = ERB.new(options[:template])
          b = Proc.new { binding }.call
          options.each do |key, value|
            next if key == :template
            eval "#{key} = options[:#{key}]", b
          end
          erb.result(b)

        else
          raise ArgumentError, "no file or template given for rendering"
      end
    end

    # An instance-level reader for the class' #default_io_proc attribute.
    def default_io_proc
      self.class.default_io_proc
    end

    # Used to force connections to be made to the current task's servers.
    # Connections are normally made lazily in Capistrano--you can use this
    # to force them open before performing some operation that might be
    # time-sensitive.
    def connect!(options={})
      execute_on_servers(options) { }
    end

    def metaclass
      class << self; self; end
    end

    private
    
      def sudo_command
        configuration[:sudo] || "sudo"
      end

      def define_method(name, &block)
        metaclass.send(:define_method, name, &block)
      end

      def method_missing(sym, *args, &block)
        if @configuration.respond_to?(sym)
          @configuration.send(sym, *args, &block)
        else
          super
        end
      end

  end
end
